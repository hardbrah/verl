# vLLM Rollout è„šæœ¬é›†åˆ

è½»é‡åŒ–çš„ vLLM Rollout è„šæœ¬ï¼Œç”¨äºé«˜æ•ˆçš„æ‰¹é‡æ¨ç†ã€‚

## ğŸ“¦ åŒ…å«çš„æ–‡ä»¶

### æ ¸å¿ƒè„šæœ¬
- **`vllm_rollout.py`**: ä¸»è¦çš„ vLLM rollout è„šæœ¬ï¼ˆå‘½ä»¤è¡Œç‰ˆæœ¬ï¼‰
- **`vllm_rollout_with_config.py`**: ä½¿ç”¨é…ç½®æ–‡ä»¶çš„ç‰ˆæœ¬
- **`process_rollout_results.py`**: ç»“æœå¤„ç†å·¥å…·ï¼ˆå±•å¹³ã€åˆ†æã€å¯¼å‡ºç­‰ï¼‰
- **`test_vllm_rollout.py`**: å¿«é€Ÿæµ‹è¯•è„šæœ¬

### è¾…åŠ©è„šæœ¬
- **`run_vllm_rollout.sh`**: Bash å¯åŠ¨è„šæœ¬
- **`vllm_shortcuts.sh`**: å¿«æ·å‘½ä»¤è„šæœ¬

### é…ç½®æ–‡ä»¶
- **`../configs/vllm_rollout_config.yaml`**: YAML é…ç½®æ–‡ä»¶æ¨¡æ¿

### æ–‡æ¡£
- **`../docs/VLLM_QUICKSTART.md`**: å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆ5 åˆ†é’Ÿä¸Šæ‰‹ï¼‰
- **`../docs/VLLM_ROLLOUT_GUIDE.md`**: å®Œæ•´ä½¿ç”¨æŒ‡å—
- **`README_VLLM_ROLLOUT.md`**: æœ¬æ–‡ä»¶

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1ï¸âƒ£ æœ€ç®€å•çš„æ–¹å¼ï¼ˆå¿«æ·å‘½ä»¤ï¼‰

```bash
# å¿«é€Ÿæµ‹è¯•
bash scripts/vllm_shortcuts.sh test

# æ¼”ç¤ºè¿è¡Œ
bash scripts/vllm_shortcuts.sh rollout-demo
```

### 2ï¸âƒ£ å‘½ä»¤è¡Œæ–¹å¼

```bash
python scripts/vllm_rollout.py \
    --model_path /datacenter/models/Qwen/Qwen3-4B-Instruct-2507 \
    --input your_input.parquet \
    --output your_output.parquet \
    --n_samples 8 \
    --max_tokens 2048
```

### 3ï¸âƒ£ é…ç½®æ–‡ä»¶æ–¹å¼

```bash
# ç¼–è¾‘é…ç½®
vim configs/vllm_rollout_config.yaml

# è¿è¡Œ
python scripts/vllm_rollout_with_config.py \
    --config configs/vllm_rollout_config.yaml \
    --input your_input.parquet \
    --output your_output.parquet
```

è¯¦ç»†è¯´æ˜è¯·æŸ¥çœ‹ [å¿«é€Ÿå¼€å§‹æŒ‡å—](../docs/VLLM_QUICKSTART.md)

## âœ¨ ä¸»è¦ç‰¹æ€§

- âœ… **é«˜æ€§èƒ½**: ä½¿ç”¨ vLLM å¼•æ“ï¼Œååé‡æå‡ 2-5x
- âœ… **æ˜“ç”¨**: æ”¯æŒå‘½ä»¤è¡Œã€é…ç½®æ–‡ä»¶ã€Bash è„šæœ¬å¤šç§æ–¹å¼
- âœ… **çµæ´»**: ä¸°å¯Œçš„é‡‡æ ·å‚æ•°é…ç½®
- âœ… **å¤š GPU**: æ”¯æŒå¼ é‡å¹¶è¡Œ
- âœ… **å®Œæ•´å·¥å…·é“¾**: åŒ…å«æ•°æ®å¤„ç†ã€åˆ†æã€å¯¼å‡ºç­‰å·¥å…·
- âœ… **è¯¦ç»†æ–‡æ¡£**: å¿«é€Ÿå¼€å§‹ + å®Œæ•´æŒ‡å—

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ–¹æ¡ˆ | ååé‡ | æ˜¾å­˜æ•ˆç‡ | é€‚ç”¨åœºæ™¯ |
|------|--------|----------|----------|
| vLLM Rollout | ğŸš€ğŸš€ğŸš€ é«˜ | ğŸ’ª ä¼˜ç§€ | å¤§è§„æ¨¡æ‰¹é‡æ¨ç† |
| Transformers | âš¡ ä¸€èˆ¬ | ğŸ‘ ä¸€èˆ¬ | å°è§„æ¨¡æµ‹è¯• |
| verl å®Œæ•´æ¡†æ¶ | ğŸš€ğŸš€ğŸš€ é«˜ | ğŸ’ª ä¼˜ç§€ | å®Œæ•´ RLHF è®­ç»ƒ |

**æ¨èåœºæ™¯**: åªéœ€è¦ç”Ÿæˆå“åº”ï¼Œä¸éœ€è¦è®­ç»ƒçš„åœºæ™¯

## ğŸ“– æ–‡æ¡£

- ğŸš€ [å¿«é€Ÿå¼€å§‹æŒ‡å—](../docs/VLLM_QUICKSTART.md) - 5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹
- ğŸ“š [å®Œæ•´ä½¿ç”¨æŒ‡å—](../docs/VLLM_ROLLOUT_GUIDE.md) - è¯¦ç»†é…ç½®å’Œé«˜çº§ç”¨æ³•
- âš™ï¸ [é…ç½®æ–‡ä»¶ç¤ºä¾‹](../configs/vllm_rollout_config.yaml)

## ğŸ› ï¸ å·¥å…·ä½¿ç”¨

### ä¸»è„šæœ¬: vllm_rollout.py

```bash
# æŸ¥çœ‹å¸®åŠ©
python scripts/vllm_rollout.py --help

# åŸºæœ¬ç”¨æ³•
python scripts/vllm_rollout.py \
    --model_path MODEL_PATH \
    --input INPUT.parquet \
    --output OUTPUT.parquet \
    [å¯é€‰å‚æ•°...]

# é‡è¦å‚æ•°:
#   --n_samples N          æ¯ä¸ª prompt ç”Ÿæˆå¤šå°‘ä¸ªå“åº”
#   --max_tokens N         æœ€å¤§ç”Ÿæˆ token æ•°
#   --temperature FLOAT    é‡‡æ ·æ¸©åº¦
#   --top_p FLOAT          Top-p sampling
#   --tensor_parallel_size N  å¼ é‡å¹¶è¡Œå¤§å°ï¼ˆGPU æ•°é‡ï¼‰
#   --gpu_memory_utilization FLOAT  æ˜¾å­˜åˆ©ç”¨ç‡ï¼ˆ0-1ï¼‰
```

### ç»“æœå¤„ç†: process_rollout_results.py

```bash
# æŸ¥çœ‹å¸®åŠ©
python scripts/process_rollout_results.py --help

# å±•å¹³å“åº”ï¼ˆå°†å¤šä¸ªå“åº”å±•å¼€ä¸ºå¤šè¡Œï¼‰
python scripts/process_rollout_results.py flatten \
    --input output.parquet \
    --output flattened.parquet

# ç»Ÿè®¡åˆ†æ
python scripts/process_rollout_results.py analyze \
    --input output.parquet

# å¯¼å‡º JSONL
python scripts/process_rollout_results.py export \
    --input output.parquet \
    --output output.jsonl

# æŒ‰é•¿åº¦è¿‡æ»¤
python scripts/process_rollout_results.py filter \
    --input flattened.parquet \
    --output filtered.parquet \
    --min_length 100 \
    --max_length 5000
```

### å¿«æ·å‘½ä»¤: vllm_shortcuts.sh

```bash
# æŸ¥çœ‹å¸®åŠ©
bash scripts/vllm_shortcuts.sh help

# å¿«é€Ÿæµ‹è¯•
bash scripts/vllm_shortcuts.sh test

# æ¼”ç¤ºè¿è¡Œ
bash scripts/vllm_shortcuts.sh rollout-demo

# åˆ†æç»“æœ
bash scripts/vllm_shortcuts.sh analyze output.parquet

# å±•å¹³ç»“æœ
bash scripts/vllm_shortcuts.sh flatten output.parquet flat.parquet

# å¯¼å‡º JSONL
bash scripts/vllm_shortcuts.sh export output.parquet output.jsonl
```

## ğŸ“ è¾“å…¥è¾“å‡ºæ ¼å¼

### è¾“å…¥æ ¼å¼

Parquet æ–‡ä»¶ï¼Œå¿…é¡»åŒ…å« `prompt` åˆ—ï¼š

```python
import pandas as pd

df = pd.DataFrame({
    'q_id': [0, 1],
    'prompt': [
        [{"role": "user", "content": "Question 1"}],
        [{"role": "user", "content": "Question 2"}]
    ]
})
```

### è¾“å‡ºæ ¼å¼

Parquet æ–‡ä»¶ï¼ŒåŒ…å«åŸå§‹åˆ— + `responses` åˆ—ï¼š

```python
# æ¯è¡Œçš„ responses æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å« n_samples ä¸ªå“åº”
df = pd.read_parquet('output.parquet')
responses = df.iloc[0]['responses']  # åˆ—è¡¨ï¼Œé•¿åº¦ä¸º n_samples
```

## ğŸ”§ å¸¸è§é…ç½®

### å• GPU (A100 80GB)
```bash
python scripts/vllm_rollout.py \
    --tensor_parallel_size 1 \
    --gpu_memory_utilization 0.95 \
    --max_num_seqs 256 \
    ...
```

### å¤š GPU (2x A100)
```bash
python scripts/vllm_rollout.py \
    --tensor_parallel_size 2 \
    --gpu_memory_utilization 0.95 \
    --max_num_seqs 512 \
    ...
```

### æ˜¾å­˜ä¸è¶³
```bash
python scripts/vllm_rollout.py \
    --gpu_memory_utilization 0.7 \
    --max_num_seqs 64 \
    ...
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: OOM (æ˜¾å­˜ä¸è¶³)
```bash
# é™ä½æ˜¾å­˜ä½¿ç”¨
--gpu_memory_utilization 0.7 --max_num_seqs 64
```

### Q: é€Ÿåº¦å¤ªæ…¢
```bash
# å¢åŠ å¹¶å‘å’Œç¼“å­˜
--max_num_seqs 512 --enable_prefix_caching
```

### Q: å¤š GPU ä¸å·¥ä½œ
```bash
# ç¡®ä¿è®¾ç½®æ­£ç¡®çš„å¼ é‡å¹¶è¡Œ
--tensor_parallel_size 2  # åº”ç­‰äº GPU æ•°é‡
```

### Q: ç»“æœä¸å¯å¤ç°
```bash
# è®¾ç½®å›ºå®šç§å­
--seed 42
```

## ğŸ“¦ ä¾èµ–å®‰è£…

```bash
# å®‰è£… vLLM
pip install vllm

# æˆ–ä»æºç å®‰è£…
pip install git+https://github.com/vllm-project/vllm.git

# éªŒè¯å®‰è£…
python -c "import vllm; print('vLLM version:', vllm.__version__)"
```

## ğŸ“ˆ æ€§èƒ½å‚è€ƒ

### ååé‡ï¼ˆtokens/sï¼‰
- å• GPU (A100 80GB): ~2000-3000 tokens/s
- åŒ GPU (2x A100): ~4000-6000 tokens/s

### é¢„ä¼°æ—¶é—´ï¼ˆå¹³å‡æ¯å“åº” 1000 tokensï¼‰

| Prompts | Samples | å• GPU | åŒ GPU |
|---------|---------|--------|--------|
| 100     | 8       | ~5 min | ~2 min |
| 1,000   | 8       | ~45 min| ~20 min|
| 10,000  | 8       | ~7 hr  | ~3.5 hr|

## ğŸ¯ å®Œæ•´å·¥ä½œæµç¤ºä¾‹

```bash
#!/bin/bash
# 1. å‡†å¤‡è¾“å…¥æ•°æ®
python prepare_data.py --output inputs.parquet

# 2. æ‰§è¡Œ rollout
python scripts/vllm_rollout.py \
    --model_path /path/to/model \
    --input inputs.parquet \
    --output outputs.parquet \
    --n_samples 16 \
    --max_tokens 2048

# 3. åˆ†æç»“æœ
python scripts/process_rollout_results.py analyze \
    --input outputs.parquet

# 4. å±•å¹³å¹¶è¿‡æ»¤
python scripts/process_rollout_results.py flatten \
    --input outputs.parquet \
    --output flat.parquet

python scripts/process_rollout_results.py filter \
    --input flat.parquet \
    --output filtered.parquet \
    --min_length 100

# 5. å¯¼å‡º
python scripts/process_rollout_results.py export \
    --input filtered.parquet \
    --output final.jsonl

echo "âœ“ å®Œæˆï¼"
```

## ğŸ“„ è®¸å¯è¯

Apache License 2.0

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

---

**å¿«é€Ÿé“¾æ¥**:
- [å¿«é€Ÿå¼€å§‹](../docs/VLLM_QUICKSTART.md)
- [å®Œæ•´æŒ‡å—](../docs/VLLM_ROLLOUT_GUIDE.md)
- [é…ç½®æ–‡ä»¶](../configs/vllm_rollout_config.yaml)



