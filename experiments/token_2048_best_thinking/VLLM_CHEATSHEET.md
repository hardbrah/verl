# vLLM Rollout å¿«é€Ÿå‚è€ƒå¡ç‰‡

> ä¸€é¡µçº¸é€ŸæŸ¥è¡¨ - æ‰“å°æˆ–ä¿å­˜åˆ°æ¡Œé¢

## ğŸš€ ä¸€åˆ†é’Ÿå¼€å§‹

```bash
# 1. å¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èé¦–æ¬¡ä½¿ç”¨ï¼‰
bash scripts/vllm_shortcuts.sh test

# 2. åŸºæœ¬ä½¿ç”¨
python scripts/vllm_rollout.py \
    --model_path /path/to/model \
    --input input.parquet \
    --output output.parquet

# 3. æŸ¥çœ‹å¸®åŠ©
python scripts/vllm_rollout.py --help
```

## ğŸ“‹ å¸¸ç”¨å‘½ä»¤

### å¿«æ·å‘½ä»¤ï¼ˆæœ€ç®€å•ï¼‰

```bash
bash scripts/vllm_shortcuts.sh test          # å¿«é€Ÿæµ‹è¯•
bash scripts/vllm_shortcuts.sh rollout-demo  # æ¼”ç¤ºè¿è¡Œ
bash scripts/vllm_shortcuts.sh analyze FILE  # åˆ†æç»“æœ
bash scripts/vllm_shortcuts.sh flatten IN OUT # å±•å¹³ç»“æœ
```

### ä¸»è„šæœ¬

```bash
# åŸºæœ¬
python scripts/vllm_rollout.py \
    --model_path MODEL --input IN --output OUT

# è‡ªå®šä¹‰é‡‡æ ·
python scripts/vllm_rollout.py \
    --model_path MODEL --input IN --output OUT \
    --n_samples 16 --max_tokens 4096 --temperature 0.8

# å¤š GPU
python scripts/vllm_rollout.py \
    --model_path MODEL --input IN --output OUT \
    --tensor_parallel_size 2 --gpu_memory_utilization 0.95
```

### ç»“æœå¤„ç†

```bash
# å±•å¹³ï¼ˆæ¯ä¸ªå“åº”ä¸€è¡Œï¼‰
python scripts/process_rollout_results.py flatten \
    --input output.parquet --output flat.parquet

# ç»Ÿè®¡åˆ†æ
python scripts/process_rollout_results.py analyze \
    --input output.parquet

# å¯¼å‡º JSONL
python scripts/process_rollout_results.py export \
    --input output.parquet --output output.jsonl

# æŒ‰é•¿åº¦è¿‡æ»¤
python scripts/process_rollout_results.py filter \
    --input flat.parquet --output filtered.parquet \
    --min_length 100 --max_length 5000
```

## âš™ï¸ é‡è¦å‚æ•°

### é‡‡æ ·å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--n_samples` | 8 | æ¯ä¸ª prompt ç”Ÿæˆå‡ ä¸ªå“åº” |
| `--max_tokens` | 2048 | æœ€å¤§ç”Ÿæˆ token æ•° |
| `--temperature` | 1.0 | é‡‡æ ·æ¸©åº¦ï¼ˆè¶Šä½è¶Šç¡®å®šï¼‰ |
| `--top_p` | 0.95 | Top-p sampling |
| `--seed` | 42 | éšæœºç§å­ï¼ˆå¯å¤ç°ï¼‰ |

### æ€§èƒ½å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--tensor_parallel_size` | 1 | GPU æ•°é‡ |
| `--gpu_memory_utilization` | 0.9 | æ˜¾å­˜åˆ©ç”¨ç‡ (0-1) |
| `--max_num_seqs` | 256 | æœ€å¤§å¹¶å‘åºåˆ—æ•° |
| `--enable_prefix_caching` | True | å¯ç”¨å‰ç¼€ç¼“å­˜ |

## ğŸ›ï¸ å¸¸ç”¨é…ç½®

### å• GPU é«˜æ€§èƒ½
```bash
--tensor_parallel_size 1 \
--gpu_memory_utilization 0.95 \
--max_num_seqs 256
```

### åŒ GPU é«˜æ€§èƒ½
```bash
--tensor_parallel_size 2 \
--gpu_memory_utilization 0.95 \
--max_num_seqs 512
```

### æ˜¾å­˜ä¸è¶³
```bash
--gpu_memory_utilization 0.7 \
--max_num_seqs 64
```

### è°ƒè¯•æ¨¡å¼
```bash
--enforce_eager \
--gpu_memory_utilization 0.5
```

## ğŸ“ æ–‡ä»¶æ ¼å¼

### è¾“å…¥ (Parquet)

```python
import pandas as pd

df = pd.DataFrame({
    'prompt': [
        [{"role": "user", "content": "é—®é¢˜1"}],
        [{"role": "user", "content": "é—®é¢˜2"}]
    ]
})
df.to_parquet('input.parquet')
```

### è¾“å‡º (Parquet)

```python
df = pd.read_parquet('output.parquet')
# df['responses'] æ˜¯åˆ—è¡¨ï¼ŒåŒ…å« n_samples ä¸ªå“åº”
print(df.iloc[0]['responses'])  # ç¬¬ä¸€ä¸ª prompt çš„æ‰€æœ‰å“åº”
```

## ğŸ› å¸¸è§é—®é¢˜é€ŸæŸ¥

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| **OOM æ˜¾å­˜ä¸è¶³** | `--gpu_memory_utilization 0.7 --max_num_seqs 64` |
| **é€Ÿåº¦å¤ªæ…¢** | `--max_num_seqs 512 --enable_prefix_caching` |
| **å¤š GPU ä¸å·¥ä½œ** | æ£€æŸ¥ `--tensor_parallel_size` æ˜¯å¦ç­‰äº GPU æ•° |
| **ç»“æœä¸å¯å¤ç°** | è®¾ç½® `--seed 42` |
| **CUDA error** | é™ä½ `--max_num_seqs` æˆ– `--gpu_memory_utilization` |

## ğŸ“Š æ€§èƒ½å‚è€ƒ

### ååé‡ (tokens/s)

- **å• A100**: ~2000-3000
- **åŒ A100**: ~4000-6000

### æ—¶é—´é¢„ä¼°ï¼ˆ1000 prompts Ã— 8 samples Ã— 1000 tokensï¼‰

- **å• A100**: ~45 åˆ†é’Ÿ
- **åŒ A100**: ~20 åˆ†é’Ÿ

## ğŸ”— å¿«é€Ÿé“¾æ¥

| èµ„æº | ä½ç½® |
|------|------|
| å¿«é€Ÿå¼€å§‹ | `docs/VLLM_QUICKSTART.md` |
| å®Œæ•´æŒ‡å— | `docs/VLLM_ROLLOUT_GUIDE.md` |
| é…ç½®æ¨¡æ¿ | `configs/vllm_rollout_config.yaml` |
| è„šæœ¬è¯´æ˜ | `scripts/README_VLLM_ROLLOUT.md` |

## ğŸ¯ å®Œæ•´å·¥ä½œæµ

```bash
# 1. å‡†å¤‡æ•°æ®
python prepare_data.py --output input.parquet

# 2. æ‰§è¡Œ rollout
python scripts/vllm_rollout.py \
    --model_path /path/to/model \
    --input input.parquet \
    --output output.parquet \
    --n_samples 8 --max_tokens 2048

# 3. åˆ†æç»“æœ
python scripts/process_rollout_results.py analyze \
    --input output.parquet

# 4. å±•å¹³å¹¶è¿‡æ»¤
python scripts/process_rollout_results.py flatten \
    --input output.parquet --output flat.parquet

python scripts/process_rollout_results.py filter \
    --input flat.parquet --output filtered.parquet \
    --min_length 100

# 5. å¯¼å‡º
python scripts/process_rollout_results.py export \
    --input filtered.parquet --output final.jsonl
```

## ğŸ’¡ æœ€ä½³å®è·µ

1. **é¦–æ¬¡ä½¿ç”¨**: å…ˆè¿è¡Œ `bash scripts/vllm_shortcuts.sh test`
2. **è°ƒä¼˜æ€§èƒ½**: ä»ä¿å®ˆé…ç½®å¼€å§‹ï¼Œé€æ­¥å¢åŠ å¹¶å‘æ•°
3. **æ˜¾å­˜ç®¡ç†**: ç›‘æ§ `nvidia-smi`ï¼Œé¿å… OOM
4. **å¯å¤ç°æ€§**: å§‹ç»ˆè®¾ç½®å›ºå®šçš„ `--seed`
5. **æ‰¹å¤„ç†**: å¯¹å¤§æ•°æ®é›†åˆ†æ‰¹å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½

## ğŸ“ è·å–å¸®åŠ©

```bash
# å‘½ä»¤è¡Œå¸®åŠ©
python scripts/vllm_rollout.py --help
python scripts/process_rollout_results.py --help
bash scripts/vllm_shortcuts.sh help

# æŸ¥çœ‹ç¤ºä¾‹
cat docs/VLLM_QUICKSTART.md
cat docs/VLLM_ROLLOUT_GUIDE.md
```

---

**ç‰ˆæœ¬**: v1.0.0 | **æ›´æ–°**: 2025-12-25









