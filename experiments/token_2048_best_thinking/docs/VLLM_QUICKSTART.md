# vLLM Rollout å¿«é€Ÿå¼€å§‹

> 5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹ vLLM Rollout è„šæœ¬

## å‰ç½®æ¡ä»¶

```bash
# 1. ç¡®ä¿å·²å®‰è£… vLLM
pip install vllm

# 2. éªŒè¯å®‰è£…
python -c "import vllm; print('vLLM version:', vllm.__version__)"

# 3. æ£€æŸ¥ GPU
nvidia-smi
```

## æ–¹å¼ä¸€ï¼šä¸€é”®æµ‹è¯•ï¼ˆæ¨èæ–°æ‰‹ï¼‰

```bash
cd /mnt/nas/chenhaotian/verl/experiments/token_2048_best_thinking

# å¿«é€Ÿæµ‹è¯•ï¼ˆ2-3 åˆ†é’Ÿï¼‰
bash scripts/vllm_shortcuts.sh test

# å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥è¿è¡Œæ¼”ç¤º
bash scripts/vllm_shortcuts.sh rollout-demo
```

## æ–¹å¼äºŒï¼šä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/vllm_rollout.py \
    --model_path /datacenter/models/Qwen/Qwen3-4B-Instruct-2507 \
    --input outputs/stage1_sampled_questions.parquet \
    --output outputs/vllm_rollout_output.parquet

# è‡ªå®šä¹‰å‚æ•°
python scripts/vllm_rollout.py \
    --model_path /datacenter/models/Qwen/Qwen3-4B-Instruct-2507 \
    --input your_input.parquet \
    --output your_output.parquet \
    --n_samples 16 \
    --max_tokens 2048 \
    --temperature 0.8 \
    --top_p 0.95 \
    --tensor_parallel_size 1 \
    --gpu_memory_utilization 0.9
```

## æ–¹å¼ä¸‰ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶

```bash
# 1. ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
vim configs/vllm_rollout_config.yaml

# 2. è¿è¡Œ
python scripts/vllm_rollout_with_config.py \
    --config configs/vllm_rollout_config.yaml \
    --input your_input.parquet \
    --output your_output.parquet
```

## æ–¹å¼å››ï¼šä½¿ç”¨ Bash è„šæœ¬

```bash
# ä½¿ç”¨é»˜è®¤å‚æ•°
bash scripts/run_vllm_rollout.sh

# ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ï¼‰
MODEL_PATH=/path/to/model \
INPUT_PATH=input.parquet \
OUTPUT_PATH=output.parquet \
N_SAMPLES=16 \
bash scripts/run_vllm_rollout.sh
```

## å‡†å¤‡è¾“å…¥æ•°æ®

è¾“å…¥æ•°æ®å¿…é¡»æ˜¯ parquet æ ¼å¼ï¼ŒåŒ…å« `prompt` åˆ—ï¼š

### ç¤ºä¾‹ 1ï¼šä» CSV è½¬æ¢

```python
import pandas as pd

# è¯»å– CSV
df = pd.read_csv('questions.csv')

# è½¬æ¢ä¸º chat æ ¼å¼
df['prompt'] = df['question'].apply(
    lambda q: [{"role": "user", "content": q}]
)

# ä¿å­˜ä¸º parquet
df.to_parquet('input.parquet', index=False)
```

### ç¤ºä¾‹ 2ï¼šæ‰‹åŠ¨åˆ›å»º

```python
import pandas as pd

data = pd.DataFrame({
    'q_id': [0, 1, 2],
    'question': [
        "What is 2+2?",
        "Explain AI.",
        "Write a haiku."
    ],
    'prompt': [
        [{"role": "user", "content": "What is 2+2?"}],
        [{"role": "user", "content": "Explain AI."}],
        [{"role": "user", "content": "Write a haiku."}]
    ]
})

data.to_parquet('input.parquet', index=False)
```

## æŸ¥çœ‹ç»“æœ

```python
import pandas as pd

# è¯»å–ç»“æœ
df = pd.read_parquet('output.parquet')

print(f"å…± {len(df)} ä¸ª prompts")
print(f"æ¯ä¸ª prompt æœ‰ {len(df.iloc[0]['responses'])} ä¸ªå“åº”")

# æŸ¥çœ‹ç¬¬ä¸€ä¸ª prompt çš„æ‰€æœ‰å“åº”
for i, response in enumerate(df.iloc[0]['responses']):
    print(f"\nå“åº” {i+1}:")
    print(response[:200] + "...")
```

## åå¤„ç†ç»“æœ

### 1. ç»Ÿè®¡åˆ†æ

```bash
python scripts/process_rollout_results.py analyze \
    --input output.parquet
```

### 2. å±•å¹³å“åº”ï¼ˆæ¯ä¸ªå“åº”ä¸€è¡Œï¼‰

```bash
python scripts/process_rollout_results.py flatten \
    --input output.parquet \
    --output flattened_output.parquet
```

### 3. å¯¼å‡ºä¸º JSONL

```bash
python scripts/process_rollout_results.py export \
    --input output.parquet \
    --output output.jsonl
```

### 4. è¿‡æ»¤é•¿åº¦

```bash
python scripts/process_rollout_results.py filter \
    --input flattened_output.parquet \
    --output filtered_output.parquet \
    --min_length 100 \
    --max_length 5000
```

## å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

```bash
# é™ä½æ˜¾å­˜ä½¿ç”¨
python scripts/vllm_rollout.py \
    --gpu_memory_utilization 0.7 \
    --max_num_seqs 64 \
    ...
```

### Q2: å¦‚ä½•ä½¿ç”¨å¤šä¸ª GPUï¼Ÿ

```bash
# è®¾ç½®å¼ é‡å¹¶è¡Œ
python scripts/vllm_rollout.py \
    --tensor_parallel_size 2 \  # ä½¿ç”¨ 2 ä¸ª GPU
    ...
```

### Q3: å¦‚ä½•åŠ å¿«ç”Ÿæˆé€Ÿåº¦ï¼Ÿ

```bash
# å¢åŠ å¹¶å‘å’Œç¼“å­˜
python scripts/vllm_rollout.py \
    --max_num_seqs 512 \
    --enable_prefix_caching \
    --gpu_memory_utilization 0.95 \
    ...
```

### Q4: ç»“æœä¸å¯å¤ç°ï¼Ÿ

```bash
# è®¾ç½®å›ºå®šç§å­
python scripts/vllm_rollout.py \
    --seed 42 \
    ...
```

## å®Œæ•´å·¥ä½œæµç¤ºä¾‹

```bash
#!/bin/bash
# å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹

cd /mnt/nas/chenhaotian/verl/experiments/token_2048_best_thinking

# 1. å‡†å¤‡æ•°æ®
python -c "
import pandas as pd
df = pd.DataFrame({
    'q_id': list(range(10)),
    'question': [f'Question {i}' for i in range(10)],
    'prompt': [[{'role': 'user', 'content': f'Question {i}'}] for i in range(10)]
})
df.to_parquet('outputs/my_questions.parquet', index=False)
print('âœ“ æ•°æ®å‡†å¤‡å®Œæˆ')
"

# 2. æ‰§è¡Œ rollout
python scripts/vllm_rollout.py \
    --model_path /datacenter/models/Qwen/Qwen3-4B-Instruct-2507 \
    --input outputs/my_questions.parquet \
    --output outputs/my_responses.parquet \
    --n_samples 8 \
    --max_tokens 2048

# 3. åˆ†æç»“æœ
python scripts/process_rollout_results.py analyze \
    --input outputs/my_responses.parquet

# 4. å±•å¹³ç»“æœ
python scripts/process_rollout_results.py flatten \
    --input outputs/my_responses.parquet \
    --output outputs/my_responses_flat.parquet

# 5. å¯¼å‡º JSONL
python scripts/process_rollout_results.py export \
    --input outputs/my_responses.parquet \
    --output outputs/my_responses.jsonl

echo "âœ“ å®Œæˆï¼"
```

## æ€§èƒ½å‚è€ƒ

### å• GPU (A100 80GB)
- **é…ç½®**: `tensor_parallel_size=1, gpu_memory_utilization=0.95`
- **æ€§èƒ½**: ~2000-3000 tokens/s
- **é€‚ç”¨**: ä¸­å°è§„æ¨¡ä»»åŠ¡ï¼ˆ< 10K promptsï¼‰

### åŒ GPU (2x A100)
- **é…ç½®**: `tensor_parallel_size=2, gpu_memory_utilization=0.95`
- **æ€§èƒ½**: ~4000-6000 tokens/s
- **é€‚ç”¨**: å¤§è§„æ¨¡ä»»åŠ¡ï¼ˆ> 10K promptsï¼‰

### é¢„ä¼°æ—¶é—´

å‡è®¾å¹³å‡æ¯ä¸ªå“åº” 1000 tokensï¼š

| Prompts | Samples | æ€» Tokens | å• GPU æ—¶é—´ | åŒ GPU æ—¶é—´ |
|---------|---------|-----------|-------------|-------------|
| 100     | 8       | 800K      | ~5 åˆ†é’Ÿ     | ~2 åˆ†é’Ÿ     |
| 1,000   | 8       | 8M        | ~45 åˆ†é’Ÿ    | ~20 åˆ†é’Ÿ    |
| 10,000  | 8       | 80M       | ~7 å°æ—¶     | ~3.5 å°æ—¶   |

## ä¸‹ä¸€æ­¥

- ğŸ“š é˜…è¯»å®Œæ•´æ–‡æ¡£: [docs/VLLM_ROLLOUT_GUIDE.md](VLLM_ROLLOUT_GUIDE.md)
- ğŸ”§ æŸ¥çœ‹é«˜çº§é…ç½®: [configs/vllm_rollout_config.yaml](../configs/vllm_rollout_config.yaml)
- ğŸ’¡ æŸ¥çœ‹æ›´å¤šç¤ºä¾‹: [scripts/](../scripts/)

## è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹å‘½ä»¤è¡Œå¸®åŠ©
python scripts/vllm_rollout.py --help

# æŸ¥çœ‹å¿«æ·å‘½ä»¤å¸®åŠ©
bash scripts/vllm_shortcuts.sh help

# æŸ¥çœ‹å¤„ç†å·¥å…·å¸®åŠ©
python scripts/process_rollout_results.py --help
```

ç¥ä½¿ç”¨æ„‰å¿«ï¼ ğŸš€



